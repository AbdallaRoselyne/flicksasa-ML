{"filter":false,"title":"collab.py","tooltip":"/collab.py","undoManager":{"mark":54,"position":54,"stack":[[{"start":{"row":0,"column":0},"end":{"row":80,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","import numpy as np","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data and user profile data from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","# Ensure user interactions have the necessary columns","if not {'user_id', 'movie_id', 'rating'}.issubset(user_interactions_df.columns):","    raise KeyError(\"User interactions data must contain 'user_id', 'movie_id', and 'rating' columns\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)","","# Compute cosine similarity between users","user_similarity = cosine_similarity(user_item_matrix)","user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)","","# Function to recommend movies using collaborative filtering","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_similarity_df.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get similar users","    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]","","    # Get the movies rated by the user","    user_ratings = user_item_matrix.loc[user_id]","","    # Get ratings from similar users","    similar_users_ratings = user_item_matrix.loc[similar_users]","","    # Compute a weighted average of the ratings of similar users","    weighted_ratings = similar_users_ratings.T.dot(user_similarity_df[user_id].loc[similar_users])","","    # Recommend the top-rated movies that the user has not yet rated","    recommendations = weighted_ratings[~user_ratings.index.isin(user_ratings[user_ratings > 0].index)]","    recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","","    return movies_df[movies_df['movie_id'].isin(recommendations.index)][['title', 'description', 'type', 'rating']]","","# Test function to verify the recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Example user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Collaborative Filtering Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":134}],[{"start":{"row":24,"column":26},"end":{"row":24,"column":27},"action":"remove","lines":["i"],"id":135},{"start":{"row":24,"column":25},"end":{"row":24,"column":26},"action":"remove","lines":["_"]}],[{"start":{"row":24,"column":25},"end":{"row":24,"column":26},"action":"insert","lines":["I"],"id":136}],[{"start":{"row":24,"column":14},"end":{"row":24,"column":15},"action":"remove","lines":["i"],"id":137},{"start":{"row":24,"column":13},"end":{"row":24,"column":14},"action":"remove","lines":["_"]}],[{"start":{"row":24,"column":13},"end":{"row":24,"column":14},"action":"insert","lines":["I"],"id":138}],[{"start":{"row":28,"column":58},"end":{"row":28,"column":59},"action":"remove","lines":["i"],"id":139},{"start":{"row":28,"column":57},"end":{"row":28,"column":58},"action":"remove","lines":["_"]}],[{"start":{"row":28,"column":57},"end":{"row":28,"column":58},"action":"insert","lines":["I"],"id":140}],[{"start":{"row":28,"column":77},"end":{"row":28,"column":78},"action":"remove","lines":["i"],"id":141},{"start":{"row":28,"column":76},"end":{"row":28,"column":77},"action":"remove","lines":["_"]}],[{"start":{"row":28,"column":76},"end":{"row":28,"column":77},"action":"insert","lines":["I"],"id":142}],[{"start":{"row":37,"column":51},"end":{"row":37,"column":52},"action":"remove","lines":["i"],"id":143},{"start":{"row":37,"column":50},"end":{"row":37,"column":51},"action":"remove","lines":["_"]}],[{"start":{"row":37,"column":50},"end":{"row":37,"column":51},"action":"insert","lines":["I"],"id":144}],[{"start":{"row":0,"column":0},"end":{"row":80,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","import numpy as np","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data and user profile data from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","# Ensure user interactions have the necessary columns","if not {'userId', 'movieId', 'rating'}.issubset(user_interactions_df.columns):","    raise KeyError(\"User interactions data must contain 'user_id', 'movie_id', and 'rating' columns\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","","# Compute cosine similarity between users","user_similarity = cosine_similarity(user_item_matrix)","user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)","","# Function to recommend movies using collaborative filtering","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_similarity_df.index:","        raise ValueError(f\"No user found with userId: {user_id}\")","","    # Get similar users","    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]","","    # Get the movies rated by the user","    user_ratings = user_item_matrix.loc[user_id]","","    # Get ratings from similar users","    similar_users_ratings = user_item_matrix.loc[similar_users]","","    # Compute a weighted average of the ratings of similar users","    weighted_ratings = similar_users_ratings.T.dot(user_similarity_df[user_id].loc[similar_users])","","    # Recommend the top-rated movies that the user has not yet rated","    recommendations = weighted_ratings[~user_ratings.index.isin(user_ratings[user_ratings > 0].index)]","    recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","","    return movies_df[movies_df['movie_id'].isin(recommendations.index)][['title', 'description', 'type', 'rating']]","","# Test function to verify the recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Example user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Collaborative Filtering Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":145},{"start":{"row":0,"column":0},"end":{"row":91,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data and user profile data from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure user interactions have the necessary columns","if not {'userId', 'movieId', 'rating'}.issubset(user_interactions_df.columns):","    raise KeyError(\"User interactions data must contain 'userId', 'movieId', and 'rating' columns\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Compute cosine similarity between users","user_similarity = cosine_similarity(user_item_matrix)","user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)","print(f\"User similarity matrix shape: {user_similarity_df.shape}\")","","# Function to recommend movies using collaborative filtering","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_similarity_df.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    print(f\"Generating recommendations for user_id: {user_id}\")","","    # Get similar users","    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]","    print(f\"Found {len(similar_users)} similar users\")","","    # Get the movies rated by the user","    user_ratings = user_item_matrix.loc[user_id]","    print(f\"User has rated {len(user_ratings[user_ratings > 0])} movies\")","","    # Get ratings from similar users","    similar_users_ratings = user_item_matrix.loc[similar_users]","","    # Compute a weighted average of the ratings of similar users","    weighted_ratings = similar_users_ratings.T.dot(user_similarity_df[user_id].loc[similar_users])","","    # Recommend the top-rated movies that the user has not yet rated","    recommendations = weighted_ratings[~user_ratings.index.isin(user_ratings[user_ratings > 0].index)]","    recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","","    recommended_movies = movies_df[movies_df['movie_id'].isin(recommendations.index)][['title', 'description', 'type', 'rating']]","    print(f\"Generated {len(recommended_movies)} recommendations\")","","    return recommended_movies","","# Test function to verify the recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Example user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Collaborative Filtering Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":0,"column":0},"end":{"row":91,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data and user profile data from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure user interactions have the necessary columns","if not {'userId', 'movieId', 'rating'}.issubset(user_interactions_df.columns):","    raise KeyError(\"User interactions data must contain 'userId', 'movieId', and 'rating' columns\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Compute cosine similarity between users","user_similarity = cosine_similarity(user_item_matrix)","user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)","print(f\"User similarity matrix shape: {user_similarity_df.shape}\")","","# Function to recommend movies using collaborative filtering","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_similarity_df.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    print(f\"Generating recommendations for user_id: {user_id}\")","","    # Get similar users","    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]","    print(f\"Found {len(similar_users)} similar users\")","","    # Get the movies rated by the user","    user_ratings = user_item_matrix.loc[user_id]","    print(f\"User has rated {len(user_ratings[user_ratings > 0])} movies\")","","    # Get ratings from similar users","    similar_users_ratings = user_item_matrix.loc[similar_users]","","    # Compute a weighted average of the ratings of similar users","    weighted_ratings = similar_users_ratings.T.dot(user_similarity_df[user_id].loc[similar_users])","","    # Recommend the top-rated movies that the user has not yet rated","    recommendations = weighted_ratings[~user_ratings.index.isin(user_ratings[user_ratings > 0].index)]","    recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","","    recommended_movies = movies_df[movies_df['movie_id'].isin(recommendations.index)][['title', 'description', 'type', 'rating']]","    print(f\"Generated {len(recommended_movies)} recommendations\")","","    return recommended_movies","","# Test function to verify the recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Example user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Collaborative Filtering Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":146},{"start":{"row":0,"column":0},"end":{"row":97,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profiles, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure user interactions have the necessary columns","if not {'userId', 'movieId', 'rating'}.issubset(user_interactions_df.columns):","    raise KeyError(\"User interactions data must contain 'userId', 'movieId', and 'rating' columns\")","","# Handle duplicates by averaging the ratings for each (userId, movieId) combination","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).rating.mean().reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Compute cosine similarity between users","user_similarity = cosine_similarity(user_item_matrix)","user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)","print(f\"User similarity matrix shape: {user_similarity_df.shape}\")","","# Function to recommend movies using collaborative filtering","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_similarity_df.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    print(f\"Generating recommendations for user_id: {user_id}\")","","    # Get similar users","    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]","    print(f\"Found {len(similar_users)} similar users\")","","    # Get the movies rated by the user","    user_ratings = user_item_matrix.loc[user_id]","    print(f\"User has rated {len(user_ratings[user_ratings > 0])} movies\")","","    # Get ratings from similar users","    similar_users_ratings = user_item_matrix.loc[similar_users]","","    # Compute a weighted average of the ratings of similar users","    weighted_ratings = similar_users_ratings.T.dot(user_similarity_df[user_id].loc[similar_users])","","    # Recommend the top-rated movies that the user has not yet rated","    recommendations = weighted_ratings[~user_ratings.index.isin(user_ratings[user_ratings > 0].index)]","    recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","","    recommended_movies = movies_df[movies_df['movie_id'].isin(recommendations.index)][['title', 'description', 'type', 'rating']]","    print(f\"Generated {len(recommended_movies)} recommendations\")","","    return recommended_movies","","# Test function to verify the recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Example user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Collaborative Filtering Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":0,"column":0},"end":{"row":97,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profiles, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure user interactions have the necessary columns","if not {'userId', 'movieId', 'rating'}.issubset(user_interactions_df.columns):","    raise KeyError(\"User interactions data must contain 'userId', 'movieId', and 'rating' columns\")","","# Handle duplicates by averaging the ratings for each (userId, movieId) combination","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).rating.mean().reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Compute cosine similarity between users","user_similarity = cosine_similarity(user_item_matrix)","user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)","print(f\"User similarity matrix shape: {user_similarity_df.shape}\")","","# Function to recommend movies using collaborative filtering","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_similarity_df.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    print(f\"Generating recommendations for user_id: {user_id}\")","","    # Get similar users","    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]","    print(f\"Found {len(similar_users)} similar users\")","","    # Get the movies rated by the user","    user_ratings = user_item_matrix.loc[user_id]","    print(f\"User has rated {len(user_ratings[user_ratings > 0])} movies\")","","    # Get ratings from similar users","    similar_users_ratings = user_item_matrix.loc[similar_users]","","    # Compute a weighted average of the ratings of similar users","    weighted_ratings = similar_users_ratings.T.dot(user_similarity_df[user_id].loc[similar_users])","","    # Recommend the top-rated movies that the user has not yet rated","    recommendations = weighted_ratings[~user_ratings.index.isin(user_ratings[user_ratings > 0].index)]","    recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","","    recommended_movies = movies_df[movies_df['movie_id'].isin(recommendations.index)][['title', 'description', 'type', 'rating']]","    print(f\"Generated {len(recommended_movies)} recommendations\")","","    return recommended_movies","","# Test function to verify the recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Example user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Collaborative Filtering Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":147},{"start":{"row":0,"column":0},"end":{"row":99,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profiles, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure user interactions have the necessary columns","if not {'userId', 'movieId', 'rating'}.issubset(user_interactions_df.columns):","    raise KeyError(\"User interactions data must contain 'userId', 'movieId', and 'rating' columns\")","","# Handle duplicates by averaging the ratings for each (userId, movieId) combination","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).rating.mean().reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Compute cosine similarity between users","user_similarity = cosine_similarity(user_item_matrix)","user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)","print(f\"User similarity matrix shape: {user_similarity_df.shape}\")","","# Function to recommend movies using collaborative filtering","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_similarity_df.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    print(f\"Generating recommendations for user_id: {user_id}\")","","    # Get similar users","    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]","    print(f\"Found {len(similar_users)} similar users\")","","    # Get the movies rated by the user","    user_ratings = user_item_matrix.loc[user_id]","    print(f\"User has rated {len(user_ratings[user_ratings > 0])} movies\")","","    # Get ratings from similar users","    similar_users_ratings = user_item_matrix.loc[similar_users]","","    # Compute a weighted average of the ratings of similar users","    weighted_ratings = similar_users_ratings.T.dot(user_similarity_df[user_id].loc[similar_users])","","    # Recommend the top-rated movies that the user has not yet rated","    recommendations = weighted_ratings[~user_ratings.index.isin(user_ratings[user_ratings > 0].index)]","    recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","","    # Correct the column name for movie ID","    movie_id_column = 'movieId'  # Assuming this is the correct column name","    recommended_movies = movies_df[movies_df[movie_id_column].isin(recommendations.index)][['title', 'description', 'type', 'rating']]","    print(f\"Generated {len(recommended_movies)} recommendations\")","","    return recommended_movies","","# Test function to verify the recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Example user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Collaborative Filtering Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":0,"column":0},"end":{"row":99,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profiles, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure user interactions have the necessary columns","if not {'userId', 'movieId', 'rating'}.issubset(user_interactions_df.columns):","    raise KeyError(\"User interactions data must contain 'userId', 'movieId', and 'rating' columns\")","","# Handle duplicates by averaging the ratings for each (userId, movieId) combination","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).rating.mean().reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Compute cosine similarity between users","user_similarity = cosine_similarity(user_item_matrix)","user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)","print(f\"User similarity matrix shape: {user_similarity_df.shape}\")","","# Function to recommend movies using collaborative filtering","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_similarity_df.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    print(f\"Generating recommendations for user_id: {user_id}\")","","    # Get similar users","    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]","    print(f\"Found {len(similar_users)} similar users\")","","    # Get the movies rated by the user","    user_ratings = user_item_matrix.loc[user_id]","    print(f\"User has rated {len(user_ratings[user_ratings > 0])} movies\")","","    # Get ratings from similar users","    similar_users_ratings = user_item_matrix.loc[similar_users]","","    # Compute a weighted average of the ratings of similar users","    weighted_ratings = similar_users_ratings.T.dot(user_similarity_df[user_id].loc[similar_users])","","    # Recommend the top-rated movies that the user has not yet rated","    recommendations = weighted_ratings[~user_ratings.index.isin(user_ratings[user_ratings > 0].index)]","    recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","","    # Correct the column name for movie ID","    movie_id_column = 'movieId'  # Assuming this is the correct column name","    recommended_movies = movies_df[movies_df[movie_id_column].isin(recommendations.index)][['title', 'description', 'type', 'rating']]","    print(f\"Generated {len(recommended_movies)} recommendations\")","","    return recommended_movies","","# Test function to verify the recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Example user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Collaborative Filtering Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":148},{"start":{"row":0,"column":0},"end":{"row":99,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profiles, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure user interactions have the necessary columns","if not {'userId', 'movieId', 'rating'}.issubset(user_interactions_df.columns):","    raise KeyError(\"User interactions data must contain 'userId', 'movieId', and 'rating' columns\")","","# Handle duplicates by averaging the ratings for each (userId, movieId) combination","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).rating.mean().reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Compute cosine similarity between users","user_similarity = cosine_similarity(user_item_matrix)","user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)","print(f\"User similarity matrix shape: {user_similarity_df.shape}\")","","# Function to recommend movies using collaborative filtering","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_similarity_df.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    print(f\"Generating recommendations for user_id: {user_id}\")","","    # Get similar users","    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]","    print(f\"Found {len(similar_users)} similar users\")","","    # Get the movies rated by the user","    user_ratings = user_item_matrix.loc[user_id]","    print(f\"User has rated {len(user_ratings[user_ratings > 0])} movies\")","","    # Get ratings from similar users","    similar_users_ratings = user_item_matrix.loc[similar_users]","","    # Compute a weighted average of the ratings of similar users","    weighted_ratings = similar_users_ratings.T.dot(user_similarity_df[user_id].loc[similar_users])","","    # Recommend the top-rated movies that the user has not yet rated","    recommendations = weighted_ratings[~user_ratings.index.isin(user_ratings[user_ratings > 0].index)]","    recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","","    # Correct the column name for movie ID","    movie_id_column = 'movieId'  # Assuming this is the correct column name","    recommended_movies = movies_df[movies_df[movie_id_column].isin(recommendations.index)][['title', 'description', 'type', 'rating']]","    print(f\"Generated {len(recommended_movies)} recommendations\")","","    return recommended_movies","","# Test function to verify the recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Example user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Collaborative Filtering Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":0,"column":0},"end":{"row":99,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profiles, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure user interactions have the necessary columns","if not {'userId', 'movieId', 'rating'}.issubset(user_interactions_df.columns):","    raise KeyError(\"User interactions data must contain 'userId', 'movieId', and 'rating' columns\")","","# Handle duplicates by averaging the ratings for each (userId, movieId) combination","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).rating.mean().reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Compute cosine similarity between users","user_similarity = cosine_similarity(user_item_matrix)","user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)","print(f\"User similarity matrix shape: {user_similarity_df.shape}\")","","# Function to recommend movies using collaborative filtering","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_similarity_df.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    print(f\"Generating recommendations for user_id: {user_id}\")","","    # Get similar users","    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]","    print(f\"Found {len(similar_users)} similar users\")","","    # Get the movies rated by the user","    user_ratings = user_item_matrix.loc[user_id]","    print(f\"User has rated {len(user_ratings[user_ratings > 0])} movies\")","","    # Get ratings from similar users","    similar_users_ratings = user_item_matrix.loc[similar_users]","","    # Compute a weighted average of the ratings of similar users","    weighted_ratings = similar_users_ratings.T.dot(user_similarity_df[user_id].loc[similar_users])","","    # Recommend the top-rated movies that the user has not yet rated","    recommendations = weighted_ratings[~user_ratings.index.isin(user_ratings[user_ratings > 0].index)]","    recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","","    # Correct the column name for movie ID","    movie_id_column = 'movieId'  # Assuming this is the correct column name","    recommended_movies = movies_df[movies_df[movie_id_column].isin(recommendations.index)][['title', 'description', 'type', 'rating']]","    print(f\"Generated {len(recommended_movies)} recommendations\")","","    return recommended_movies","","# Test function to verify the recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Example user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Collaborative Filtering Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":149},{"start":{"row":0,"column":0},"end":{"row":90,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    recommended_movies = movies_df[movies_df.index.isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":0,"column":0},"end":{"row":90,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    recommended_movies = movies_df[movies_df.index.isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":150},{"start":{"row":0,"column":0},"end":{"row":90,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":0,"column":0},"end":{"row":90,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":151},{"start":{"row":0,"column":0},"end":{"row":93,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":0,"column":0},"end":{"row":93,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":152},{"start":{"row":0,"column":0},"end":{"row":105,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    # Ensure 'movieId' column exists in movies_df","    if 'movieId' not in movies_df.columns:","        raise KeyError(\"'movieId' column is missing in movies_df\")","","    # Check data types","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    # Convert types if necessary","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":0,"column":0},"end":{"row":105,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    # Ensure 'movieId' column exists in movies_df","    if 'movieId' not in movies_df.columns:","        raise KeyError(\"'movieId' column is missing in movies_df\")","","    # Check data types","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    # Convert types if necessary","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":153},{"start":{"row":0,"column":0},"end":{"row":108,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Print columns of movies_df for debugging","print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Ensure the movie dataset has a 'movieId' column","if 'movieId' not in movies_df.columns:","    raise KeyError(\"'movieId' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    # Check data types","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    # Convert types if necessary","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":0,"column":0},"end":{"row":108,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Print columns of movies_df for debugging","print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Ensure the movie dataset has a 'movieId' column","if 'movieId' not in movies_df.columns:","    raise KeyError(\"'movieId' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    # Check data types","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    # Convert types if necessary","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":154},{"start":{"row":0,"column":0},"end":{"row":107,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Add 'movieId' column to movies_df","movies_df['movieId'] = range(1, len(movies_df) + 1)","","# Print columns of movies_df for debugging","print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    # Check data types","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    # Convert types if necessary","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":0,"column":0},"end":{"row":107,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Add 'movieId' column to movies_df","movies_df['movieId'] = range(1, len(movies_df) + 1)","","# Print columns of movies_df for debugging","print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    # Check data types","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    # Convert types if necessary","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":155},{"start":{"row":0,"column":0},"end":{"row":110,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Add 'movieId' column to movies_df","movies_df['movieId'] = range(1, len(movies_df) + 1)","","# Add 'type' column based on 'year'","movies_df['type'] = movies_df['year'].apply(lambda x: 'movie' if '-' not in str(x) else 'series')","","# Print columns of movies_df for debugging","print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    # Check data types","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    # Convert types if necessary","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":88,"column":20},"end":{"row":88,"column":21},"action":"remove","lines":["2"],"id":156},{"start":{"row":88,"column":19},"end":{"row":88,"column":20},"action":"remove","lines":["2"]}],[{"start":{"row":88,"column":19},"end":{"row":88,"column":20},"action":"insert","lines":["1"],"id":157}],[{"start":{"row":0,"column":0},"end":{"row":110,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Add 'movieId' column to movies_df","movies_df['movieId'] = range(1, len(movies_df) + 1)","","# Add 'type' column based on 'year'","movies_df['type'] = movies_df['year'].apply(lambda x: 'movie' if '-' not in str(x) else 'series')","","# Print columns of movies_df for debugging","print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    # Check data types","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    # Convert types if necessary","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 1  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":158},{"start":{"row":0,"column":0},"end":{"row":214,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","from sklearn.model_selection import train_test_split","import numpy as np","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Add 'movieId' column to movies_df","movies_df['movieId'] = range(1, len(movies_df) + 1)","","# Add 'type' column based on 'year'","movies_df['type'] = movies_df['year'].apply(lambda x: 'movie' if '-' not in str(x) else 'series')","","# Print columns of movies_df for debugging","print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Split the data into training and test sets","train_df, test_df = train_test_split(user_interactions_df, test_size=0.2, random_state=42)","","print(f\"Training set size: {len(train_df)}\")","print(f\"Test set size: {len(test_df)}\")","","# Create the user-item matrix for the training set","train_user_item_matrix = train_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","","# Calculate user similarity matrix using the training set","train_user_similarity = cosine_similarity(train_user_item_matrix)","print(f\"Training User similarity matrix shape: {train_user_similarity.shape}\")","","# Function to predict ratings","def predict_rating(user_id, movie_id, user_similarity, user_item_matrix):","    if movie_id not in user_item_matrix.columns:","        return np.nan","    ","    # Get the indices of the similar users","    user_index = user_item_matrix.index.get_loc(user_id)","    user_similarities = user_similarity[user_index]","    ","    # Exclude the target user from the list of similar users","    similar_users_indices = np.argsort(user_similarities)[::-1][1:]","    ","    # Get the ratings from similar users for the given movie","    similar_users_ratings = user_item_matrix.iloc[similar_users_indices][movie_id]","    ","    # Calculate the predicted rating as a weighted average of similar users' ratings","    weighted_sum = np.dot(user_similarities[similar_users_indices], similar_users_ratings)","    sum_of_weights = np.sum(user_similarities[similar_users_indices])","    ","    if sum_of_weights == 0:","        return np.nan","    ","    return weighted_sum / sum_of_weights","","# Evaluate the model using MAE and MSE","def evaluate_model(test_df, user_similarity, user_item_matrix):","    y_true = []","    y_pred = []","","    for _, row in test_df.iterrows():","        user_id = row['userId']","        movie_id = row['movieId']","        true_rating = row['rating']","        predicted_rating = predict_rating(user_id, movie_id, user_similarity, user_item_matrix)","        ","        if not np.isnan(predicted_rating):","            y_true.append(true_rating)","            y_pred.append(predicted_rating)","    ","    mae = np.mean(np.abs(np.array(y_true) - np.array(y_pred)))","    mse = np.mean((np.array(y_true) - np.array(y_pred))**2)","    ","    return mae, mse","","# Evaluate the model using the test set","mae, mse = evaluate_model(test_df, train_user_similarity, train_user_item_matrix)","print(f\"MAE: {mae}\")","print(f\"MSE: {mse}\")","","# Function to get top k recommendations","def get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k=10):","    user_index = user_item_matrix.index.get_loc(user_id)","    user_similarities = user_similarity[user_index]","    similar_users_indices = user_similarities.argsort()[::-1][1:]","    ","    similar_users = user_item_matrix.iloc[similar_users_indices]","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]","    ","    top_recommendations = recommendations.sort_values(ascending=False).head(k)","    return top_recommendations.index","","# Evaluate precision and recall at k","def evaluate_precision_recall_at_k(test_df, user_similarity, user_item_matrix, k=10):","    precisions = []","    recalls = []","","    for user_id in test_df['userId'].unique():","        true_positive = test_df[test_df['userId'] == user_id]['movieId'].tolist()","        top_k_recommendations = get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k)","        ","        hits = len(set(true_positive) & set(top_k_recommendations))","        precision = hits / k","        recall = hits / len(true_positive)","        ","        precisions.append(precision)","        recalls.append(recall)","    ","    avg_precision = np.mean(precisions)","    avg_recall = np.mean(recalls)","    ","    return avg_precision, avg_recall","","# Evaluate the model using Precision@k and Recall@k","precision, recall = evaluate_precision_recall_at_k(test_df, train_user_similarity, train_user_item_matrix)","print(f\"Precision@10: {precision}\")","print(f\"Recall@10: {recall}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    # Check data types","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    # Convert types if necessary","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":0,"column":0},"end":{"row":214,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","from sklearn.model_selection import train_test_split","import numpy as np","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Add 'movieId' column to movies_df","movies_df['movieId'] = range(1, len(movies_df) + 1)","","# Add 'type' column based on 'year'","movies_df['type'] = movies_df['year'].apply(lambda x: 'movie' if '-' not in str(x) else 'series')","","# Print columns of movies_df for debugging","print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Split the data into training and test sets","train_df, test_df = train_test_split(user_interactions_df, test_size=0.2, random_state=42)","","print(f\"Training set size: {len(train_df)}\")","print(f\"Test set size: {len(test_df)}\")","","# Create the user-item matrix for the training set","train_user_item_matrix = train_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","","# Calculate user similarity matrix using the training set","train_user_similarity = cosine_similarity(train_user_item_matrix)","print(f\"Training User similarity matrix shape: {train_user_similarity.shape}\")","","# Function to predict ratings","def predict_rating(user_id, movie_id, user_similarity, user_item_matrix):","    if movie_id not in user_item_matrix.columns:","        return np.nan","    ","    # Get the indices of the similar users","    user_index = user_item_matrix.index.get_loc(user_id)","    user_similarities = user_similarity[user_index]","    ","    # Exclude the target user from the list of similar users","    similar_users_indices = np.argsort(user_similarities)[::-1][1:]","    ","    # Get the ratings from similar users for the given movie","    similar_users_ratings = user_item_matrix.iloc[similar_users_indices][movie_id]","    ","    # Calculate the predicted rating as a weighted average of similar users' ratings","    weighted_sum = np.dot(user_similarities[similar_users_indices], similar_users_ratings)","    sum_of_weights = np.sum(user_similarities[similar_users_indices])","    ","    if sum_of_weights == 0:","        return np.nan","    ","    return weighted_sum / sum_of_weights","","# Evaluate the model using MAE and MSE","def evaluate_model(test_df, user_similarity, user_item_matrix):","    y_true = []","    y_pred = []","","    for _, row in test_df.iterrows():","        user_id = row['userId']","        movie_id = row['movieId']","        true_rating = row['rating']","        predicted_rating = predict_rating(user_id, movie_id, user_similarity, user_item_matrix)","        ","        if not np.isnan(predicted_rating):","            y_true.append(true_rating)","            y_pred.append(predicted_rating)","    ","    mae = np.mean(np.abs(np.array(y_true) - np.array(y_pred)))","    mse = np.mean((np.array(y_true) - np.array(y_pred))**2)","    ","    return mae, mse","","# Evaluate the model using the test set","mae, mse = evaluate_model(test_df, train_user_similarity, train_user_item_matrix)","print(f\"MAE: {mae}\")","print(f\"MSE: {mse}\")","","# Function to get top k recommendations","def get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k=10):","    user_index = user_item_matrix.index.get_loc(user_id)","    user_similarities = user_similarity[user_index]","    similar_users_indices = user_similarities.argsort()[::-1][1:]","    ","    similar_users = user_item_matrix.iloc[similar_users_indices]","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]","    ","    top_recommendations = recommendations.sort_values(ascending=False).head(k)","    return top_recommendations.index","","# Evaluate precision and recall at k","def evaluate_precision_recall_at_k(test_df, user_similarity, user_item_matrix, k=10):","    precisions = []","    recalls = []","","    for user_id in test_df['userId'].unique():","        true_positive = test_df[test_df['userId'] == user_id]['movieId'].tolist()","        top_k_recommendations = get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k)","        ","        hits = len(set(true_positive) & set(top_k_recommendations))","        precision = hits / k","        recall = hits / len(true_positive)","        ","        precisions.append(precision)","        recalls.append(recall)","    ","    avg_precision = np.mean(precisions)","    avg_recall = np.mean(recalls)","    ","    return avg_precision, avg_recall","","# Evaluate the model using Precision@k and Recall@k","precision, recall = evaluate_precision_recall_at_k(test_df, train_user_similarity, train_user_item_matrix)","print(f\"Precision@10: {precision}\")","print(f\"Recall@10: {recall}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    # Check data types","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    # Convert types if necessary","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":159},{"start":{"row":0,"column":0},"end":{"row":214,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","from sklearn.model_selection import train_test_split","import numpy as np","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Add 'movieId' column to movies_df","movies_df['movieId'] = range(1, len(movies_df) + 1)","","# Add 'type' column based on 'year'","movies_df['type'] = movies_df['year'].apply(lambda x: 'movie' if '-' not in str(x) else 'series')","","# Print columns of movies_df for debugging","print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Calculate user similarity matrix","user_similarity = cosine_similarity(user_item_matrix)","print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# Split the data into training and test sets","train_df, test_df = train_test_split(user_interactions_df, test_size=0.2, random_state=42)","","print(f\"Training set size: {len(train_df)}\")","print(f\"Test set size: {len(test_df)}\")","","# Create the user-item matrix for the training set","train_user_item_matrix = train_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","","# Calculate user similarity matrix using the training set","train_user_similarity = cosine_similarity(train_user_item_matrix)","print(f\"Training User similarity matrix shape: {train_user_similarity.shape}\")","","# Function to predict ratings","def predict_rating(user_id, movie_id, user_similarity, user_item_matrix):","    if movie_id not in user_item_matrix.columns:","        return np.nan","    ","    # Get the indices of the similar users","    user_index = user_item_matrix.index.get_loc(user_id)","    user_similarities = user_similarity[user_index]","    ","    # Exclude the target user from the list of similar users","    similar_users_indices = np.argsort(user_similarities)[::-1][1:]","    ","    # Get the ratings from similar users for the given movie","    similar_users_ratings = user_item_matrix.iloc[similar_users_indices][movie_id]","    ","    # Calculate the predicted rating as a weighted average of similar users' ratings","    weighted_sum = np.dot(user_similarities[similar_users_indices], similar_users_ratings)","    sum_of_weights = np.sum(user_similarities[similar_users_indices])","    ","    if sum_of_weights == 0:","        return np.nan","    ","    return weighted_sum / sum_of_weights","","# Evaluate the model using MAE and MSE","def evaluate_model(test_df, user_similarity, user_item_matrix):","    y_true = []","    y_pred = []","","    for _, row in test_df.iterrows():","        user_id = row['userId']","        movie_id = row['movieId']","        true_rating = row['rating']","        predicted_rating = predict_rating(user_id, movie_id, user_similarity, user_item_matrix)","        ","        if not np.isnan(predicted_rating):","            y_true.append(true_rating)","            y_pred.append(predicted_rating)","    ","    mae = np.mean(np.abs(np.array(y_true) - np.array(y_pred)))","    mse = np.mean((np.array(y_true) - np.array(y_pred))**2)","    ","    return mae, mse","","# Evaluate the model using the test set","mae, mse = evaluate_model(test_df, train_user_similarity, train_user_item_matrix)","print(f\"MAE: {mae}\")","print(f\"MSE: {mse}\")","","# Function to get top k recommendations","def get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k=10):","    user_index = user_item_matrix.index.get_loc(user_id)","    user_similarities = user_similarity[user_index]","    similar_users_indices = user_similarities.argsort()[::-1][1:]","    ","    similar_users = user_item_matrix.iloc[similar_users_indices]","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]","    ","    top_recommendations = recommendations.sort_values(ascending=False).head(k)","    return top_recommendations.index","","# Evaluate precision and recall at k","def evaluate_precision_recall_at_k(test_df, user_similarity, user_item_matrix, k=10):","    precisions = []","    recalls = []","","    for user_id in test_df['userId'].unique():","        true_positive = test_df[test_df['userId'] == user_id]['movieId'].tolist()","        top_k_recommendations = get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k)","        ","        hits = len(set(true_positive) & set(top_k_recommendations))","        precision = hits / k","        recall = hits / len(true_positive)","        ","        precisions.append(precision)","        recalls.append(recall)","    ","    avg_precision = np.mean(precisions)","    avg_recall = np.mean(recalls)","    ","    return avg_precision, avg_recall","","# Evaluate the model using Precision@k and Recall@k","precision, recall = evaluate_precision_recall_at_k(test_df, train_user_similarity, train_user_item_matrix)","print(f\"Precision@10: {precision}\")","print(f\"Recall@10: {recall}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    # Get the user's similarity scores with other users","    user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    # Aggregate ratings from similar users","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","    # Get top recommendations","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    # Debugging information","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","    # Check data types","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    # Convert types if necessary","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 22  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    # Ensure recommendations are returned","    assert not recommendations.empty, \"No recommendations were generated.\"","    ","    # Verify the number of recommendations is up to n_recommendations","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    # Print the recommendations for debugging","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""]}],[{"start":{"row":192,"column":20},"end":{"row":192,"column":21},"action":"remove","lines":["2"],"id":160},{"start":{"row":192,"column":19},"end":{"row":192,"column":20},"action":"remove","lines":["2"]}],[{"start":{"row":192,"column":19},"end":{"row":192,"column":20},"action":"insert","lines":["3"],"id":161}],[{"start":{"row":192,"column":18},"end":{"row":192,"column":20},"action":"remove","lines":[" 3"],"id":162},{"start":{"row":192,"column":18},"end":{"row":192,"column":19},"action":"insert","lines":["5"]}],[{"start":{"row":0,"column":0},"end":{"row":0,"column":2},"action":"insert","lines":["# "],"id":163},{"start":{"row":1,"column":0},"end":{"row":1,"column":2},"action":"insert","lines":["# "]},{"start":{"row":2,"column":0},"end":{"row":2,"column":2},"action":"insert","lines":["# "]},{"start":{"row":3,"column":0},"end":{"row":3,"column":2},"action":"insert","lines":["# "]},{"start":{"row":4,"column":0},"end":{"row":4,"column":2},"action":"insert","lines":["# "]},{"start":{"row":5,"column":0},"end":{"row":5,"column":2},"action":"insert","lines":["# "]},{"start":{"row":7,"column":0},"end":{"row":7,"column":2},"action":"insert","lines":["# "]},{"start":{"row":8,"column":0},"end":{"row":8,"column":2},"action":"insert","lines":["# "]},{"start":{"row":9,"column":0},"end":{"row":9,"column":2},"action":"insert","lines":["# "]},{"start":{"row":10,"column":0},"end":{"row":10,"column":2},"action":"insert","lines":["# "]},{"start":{"row":11,"column":0},"end":{"row":11,"column":2},"action":"insert","lines":["# "]},{"start":{"row":12,"column":0},"end":{"row":12,"column":2},"action":"insert","lines":["# "]},{"start":{"row":14,"column":0},"end":{"row":14,"column":2},"action":"insert","lines":["# "]},{"start":{"row":15,"column":0},"end":{"row":15,"column":2},"action":"insert","lines":["# "]},{"start":{"row":16,"column":0},"end":{"row":16,"column":2},"action":"insert","lines":["# "]},{"start":{"row":17,"column":0},"end":{"row":17,"column":2},"action":"insert","lines":["# "]},{"start":{"row":19,"column":0},"end":{"row":19,"column":2},"action":"insert","lines":["# "]},{"start":{"row":20,"column":0},"end":{"row":20,"column":2},"action":"insert","lines":["# "]},{"start":{"row":21,"column":0},"end":{"row":21,"column":2},"action":"insert","lines":["# "]},{"start":{"row":22,"column":0},"end":{"row":22,"column":2},"action":"insert","lines":["# "]},{"start":{"row":24,"column":0},"end":{"row":24,"column":2},"action":"insert","lines":["# "]},{"start":{"row":25,"column":0},"end":{"row":25,"column":2},"action":"insert","lines":["# "]},{"start":{"row":26,"column":0},"end":{"row":26,"column":2},"action":"insert","lines":["# "]},{"start":{"row":28,"column":0},"end":{"row":28,"column":2},"action":"insert","lines":["# "]},{"start":{"row":29,"column":0},"end":{"row":29,"column":2},"action":"insert","lines":["# "]},{"start":{"row":31,"column":0},"end":{"row":31,"column":2},"action":"insert","lines":["# "]},{"start":{"row":32,"column":0},"end":{"row":32,"column":2},"action":"insert","lines":["# "]},{"start":{"row":34,"column":0},"end":{"row":34,"column":2},"action":"insert","lines":["# "]},{"start":{"row":35,"column":0},"end":{"row":35,"column":2},"action":"insert","lines":["# "]},{"start":{"row":37,"column":0},"end":{"row":37,"column":2},"action":"insert","lines":["# "]},{"start":{"row":38,"column":0},"end":{"row":38,"column":2},"action":"insert","lines":["# "]},{"start":{"row":39,"column":0},"end":{"row":39,"column":2},"action":"insert","lines":["# "]},{"start":{"row":41,"column":0},"end":{"row":41,"column":2},"action":"insert","lines":["# "]},{"start":{"row":42,"column":0},"end":{"row":42,"column":2},"action":"insert","lines":["# "]},{"start":{"row":43,"column":0},"end":{"row":43,"column":2},"action":"insert","lines":["# "]},{"start":{"row":45,"column":0},"end":{"row":45,"column":2},"action":"insert","lines":["# "]},{"start":{"row":46,"column":0},"end":{"row":46,"column":2},"action":"insert","lines":["# "]},{"start":{"row":47,"column":0},"end":{"row":47,"column":2},"action":"insert","lines":["# "]},{"start":{"row":49,"column":0},"end":{"row":49,"column":2},"action":"insert","lines":["# "]},{"start":{"row":50,"column":0},"end":{"row":50,"column":2},"action":"insert","lines":["# "]},{"start":{"row":51,"column":0},"end":{"row":51,"column":2},"action":"insert","lines":["# "]},{"start":{"row":53,"column":0},"end":{"row":53,"column":2},"action":"insert","lines":["# "]},{"start":{"row":54,"column":0},"end":{"row":54,"column":2},"action":"insert","lines":["# "]},{"start":{"row":56,"column":0},"end":{"row":56,"column":2},"action":"insert","lines":["# "]},{"start":{"row":57,"column":0},"end":{"row":57,"column":2},"action":"insert","lines":["# "]},{"start":{"row":59,"column":0},"end":{"row":59,"column":2},"action":"insert","lines":["# "]},{"start":{"row":60,"column":0},"end":{"row":60,"column":2},"action":"insert","lines":["# "]},{"start":{"row":62,"column":0},"end":{"row":62,"column":2},"action":"insert","lines":["# "]},{"start":{"row":63,"column":0},"end":{"row":63,"column":2},"action":"insert","lines":["# "]},{"start":{"row":64,"column":0},"end":{"row":64,"column":2},"action":"insert","lines":["# "]},{"start":{"row":66,"column":0},"end":{"row":66,"column":2},"action":"insert","lines":["# "]},{"start":{"row":67,"column":0},"end":{"row":67,"column":2},"action":"insert","lines":["# "]},{"start":{"row":68,"column":0},"end":{"row":68,"column":2},"action":"insert","lines":["# "]},{"start":{"row":69,"column":0},"end":{"row":69,"column":2},"action":"insert","lines":["# "]},{"start":{"row":71,"column":0},"end":{"row":71,"column":2},"action":"insert","lines":["# "]},{"start":{"row":72,"column":0},"end":{"row":72,"column":2},"action":"insert","lines":["# "]},{"start":{"row":73,"column":0},"end":{"row":73,"column":2},"action":"insert","lines":["# "]},{"start":{"row":75,"column":0},"end":{"row":75,"column":2},"action":"insert","lines":["# "]},{"start":{"row":76,"column":0},"end":{"row":76,"column":2},"action":"insert","lines":["# "]},{"start":{"row":78,"column":0},"end":{"row":78,"column":2},"action":"insert","lines":["# "]},{"start":{"row":79,"column":0},"end":{"row":79,"column":2},"action":"insert","lines":["# "]},{"start":{"row":81,"column":0},"end":{"row":81,"column":2},"action":"insert","lines":["# "]},{"start":{"row":82,"column":0},"end":{"row":82,"column":2},"action":"insert","lines":["# "]},{"start":{"row":83,"column":0},"end":{"row":83,"column":2},"action":"insert","lines":["# "]},{"start":{"row":85,"column":0},"end":{"row":85,"column":2},"action":"insert","lines":["# "]},{"start":{"row":86,"column":0},"end":{"row":86,"column":2},"action":"insert","lines":["# "]},{"start":{"row":88,"column":0},"end":{"row":88,"column":2},"action":"insert","lines":["# "]},{"start":{"row":90,"column":0},"end":{"row":90,"column":2},"action":"insert","lines":["# "]},{"start":{"row":91,"column":0},"end":{"row":91,"column":2},"action":"insert","lines":["# "]},{"start":{"row":92,"column":0},"end":{"row":92,"column":2},"action":"insert","lines":["# "]},{"start":{"row":93,"column":0},"end":{"row":93,"column":2},"action":"insert","lines":["# "]},{"start":{"row":95,"column":0},"end":{"row":95,"column":2},"action":"insert","lines":["# "]},{"start":{"row":96,"column":0},"end":{"row":96,"column":2},"action":"insert","lines":["# "]},{"start":{"row":97,"column":0},"end":{"row":97,"column":2},"action":"insert","lines":["# "]},{"start":{"row":98,"column":0},"end":{"row":98,"column":2},"action":"insert","lines":["# "]},{"start":{"row":99,"column":0},"end":{"row":99,"column":2},"action":"insert","lines":["# "]},{"start":{"row":101,"column":0},"end":{"row":101,"column":2},"action":"insert","lines":["# "]},{"start":{"row":102,"column":0},"end":{"row":102,"column":2},"action":"insert","lines":["# "]},{"start":{"row":103,"column":0},"end":{"row":103,"column":2},"action":"insert","lines":["# "]},{"start":{"row":105,"column":0},"end":{"row":105,"column":2},"action":"insert","lines":["# "]},{"start":{"row":106,"column":0},"end":{"row":106,"column":2},"action":"insert","lines":["# "]},{"start":{"row":108,"column":0},"end":{"row":108,"column":2},"action":"insert","lines":["# "]},{"start":{"row":110,"column":0},"end":{"row":110,"column":2},"action":"insert","lines":["# "]},{"start":{"row":111,"column":0},"end":{"row":111,"column":2},"action":"insert","lines":["# "]},{"start":{"row":112,"column":0},"end":{"row":112,"column":2},"action":"insert","lines":["# "]},{"start":{"row":113,"column":0},"end":{"row":113,"column":2},"action":"insert","lines":["# "]},{"start":{"row":115,"column":0},"end":{"row":115,"column":2},"action":"insert","lines":["# "]},{"start":{"row":116,"column":0},"end":{"row":116,"column":2},"action":"insert","lines":["# "]},{"start":{"row":117,"column":0},"end":{"row":117,"column":2},"action":"insert","lines":["# "]},{"start":{"row":118,"column":0},"end":{"row":118,"column":2},"action":"insert","lines":["# "]},{"start":{"row":119,"column":0},"end":{"row":119,"column":2},"action":"insert","lines":["# "]},{"start":{"row":121,"column":0},"end":{"row":121,"column":2},"action":"insert","lines":["# "]},{"start":{"row":122,"column":0},"end":{"row":122,"column":2},"action":"insert","lines":["# "]},{"start":{"row":123,"column":0},"end":{"row":123,"column":2},"action":"insert","lines":["# "]},{"start":{"row":124,"column":0},"end":{"row":124,"column":2},"action":"insert","lines":["# "]},{"start":{"row":126,"column":0},"end":{"row":126,"column":2},"action":"insert","lines":["# "]},{"start":{"row":127,"column":0},"end":{"row":127,"column":2},"action":"insert","lines":["# "]},{"start":{"row":129,"column":0},"end":{"row":129,"column":2},"action":"insert","lines":["# "]},{"start":{"row":130,"column":0},"end":{"row":130,"column":2},"action":"insert","lines":["# "]},{"start":{"row":131,"column":0},"end":{"row":131,"column":2},"action":"insert","lines":["# "]},{"start":{"row":132,"column":0},"end":{"row":132,"column":2},"action":"insert","lines":["# "]},{"start":{"row":134,"column":0},"end":{"row":134,"column":2},"action":"insert","lines":["# "]},{"start":{"row":135,"column":0},"end":{"row":135,"column":2},"action":"insert","lines":["# "]},{"start":{"row":136,"column":0},"end":{"row":136,"column":2},"action":"insert","lines":["# "]},{"start":{"row":138,"column":0},"end":{"row":138,"column":2},"action":"insert","lines":["# "]},{"start":{"row":139,"column":0},"end":{"row":139,"column":2},"action":"insert","lines":["# "]},{"start":{"row":140,"column":0},"end":{"row":140,"column":2},"action":"insert","lines":["# "]},{"start":{"row":142,"column":0},"end":{"row":142,"column":2},"action":"insert","lines":["# "]},{"start":{"row":143,"column":0},"end":{"row":143,"column":2},"action":"insert","lines":["# "]},{"start":{"row":145,"column":0},"end":{"row":145,"column":2},"action":"insert","lines":["# "]},{"start":{"row":146,"column":0},"end":{"row":146,"column":2},"action":"insert","lines":["# "]},{"start":{"row":148,"column":0},"end":{"row":148,"column":2},"action":"insert","lines":["# "]},{"start":{"row":150,"column":0},"end":{"row":150,"column":2},"action":"insert","lines":["# "]},{"start":{"row":151,"column":0},"end":{"row":151,"column":2},"action":"insert","lines":["# "]},{"start":{"row":152,"column":0},"end":{"row":152,"column":2},"action":"insert","lines":["# "]},{"start":{"row":153,"column":0},"end":{"row":153,"column":2},"action":"insert","lines":["# "]},{"start":{"row":155,"column":0},"end":{"row":155,"column":2},"action":"insert","lines":["# "]},{"start":{"row":156,"column":0},"end":{"row":156,"column":2},"action":"insert","lines":["# "]},{"start":{"row":157,"column":0},"end":{"row":157,"column":2},"action":"insert","lines":["# "]},{"start":{"row":158,"column":0},"end":{"row":158,"column":2},"action":"insert","lines":["# "]},{"start":{"row":160,"column":0},"end":{"row":160,"column":2},"action":"insert","lines":["# "]},{"start":{"row":161,"column":0},"end":{"row":161,"column":2},"action":"insert","lines":["# "]},{"start":{"row":162,"column":0},"end":{"row":162,"column":2},"action":"insert","lines":["# "]},{"start":{"row":164,"column":0},"end":{"row":164,"column":2},"action":"insert","lines":["# "]},{"start":{"row":165,"column":0},"end":{"row":165,"column":2},"action":"insert","lines":["# "]},{"start":{"row":167,"column":0},"end":{"row":167,"column":2},"action":"insert","lines":["# "]},{"start":{"row":168,"column":0},"end":{"row":168,"column":2},"action":"insert","lines":["# "]},{"start":{"row":169,"column":0},"end":{"row":169,"column":2},"action":"insert","lines":["# "]},{"start":{"row":170,"column":0},"end":{"row":170,"column":2},"action":"insert","lines":["# "]},{"start":{"row":172,"column":0},"end":{"row":172,"column":2},"action":"insert","lines":["# "]},{"start":{"row":173,"column":0},"end":{"row":173,"column":2},"action":"insert","lines":["# "]},{"start":{"row":174,"column":0},"end":{"row":174,"column":2},"action":"insert","lines":["# "]},{"start":{"row":176,"column":0},"end":{"row":176,"column":2},"action":"insert","lines":["# "]},{"start":{"row":177,"column":0},"end":{"row":177,"column":2},"action":"insert","lines":["# "]},{"start":{"row":179,"column":0},"end":{"row":179,"column":2},"action":"insert","lines":["# "]},{"start":{"row":180,"column":0},"end":{"row":180,"column":2},"action":"insert","lines":["# "]},{"start":{"row":181,"column":0},"end":{"row":181,"column":2},"action":"insert","lines":["# "]},{"start":{"row":183,"column":0},"end":{"row":183,"column":2},"action":"insert","lines":["# "]},{"start":{"row":184,"column":0},"end":{"row":184,"column":2},"action":"insert","lines":["# "]},{"start":{"row":185,"column":0},"end":{"row":185,"column":2},"action":"insert","lines":["# "]},{"start":{"row":187,"column":0},"end":{"row":187,"column":2},"action":"insert","lines":["# "]},{"start":{"row":188,"column":0},"end":{"row":188,"column":2},"action":"insert","lines":["# "]},{"start":{"row":190,"column":0},"end":{"row":190,"column":2},"action":"insert","lines":["# "]},{"start":{"row":191,"column":0},"end":{"row":191,"column":2},"action":"insert","lines":["# "]},{"start":{"row":192,"column":0},"end":{"row":192,"column":2},"action":"insert","lines":["# "]},{"start":{"row":193,"column":0},"end":{"row":193,"column":2},"action":"insert","lines":["# "]},{"start":{"row":194,"column":0},"end":{"row":194,"column":2},"action":"insert","lines":["# "]},{"start":{"row":195,"column":0},"end":{"row":195,"column":2},"action":"insert","lines":["# "]},{"start":{"row":196,"column":0},"end":{"row":196,"column":2},"action":"insert","lines":["# "]},{"start":{"row":197,"column":0},"end":{"row":197,"column":2},"action":"insert","lines":["# "]},{"start":{"row":199,"column":0},"end":{"row":199,"column":2},"action":"insert","lines":["# "]},{"start":{"row":200,"column":0},"end":{"row":200,"column":2},"action":"insert","lines":["# "]},{"start":{"row":202,"column":0},"end":{"row":202,"column":2},"action":"insert","lines":["# "]},{"start":{"row":203,"column":0},"end":{"row":203,"column":2},"action":"insert","lines":["# "]},{"start":{"row":205,"column":0},"end":{"row":205,"column":2},"action":"insert","lines":["# "]},{"start":{"row":206,"column":0},"end":{"row":206,"column":2},"action":"insert","lines":["# "]},{"start":{"row":208,"column":0},"end":{"row":208,"column":2},"action":"insert","lines":["# "]},{"start":{"row":209,"column":0},"end":{"row":209,"column":2},"action":"insert","lines":["# "]},{"start":{"row":210,"column":0},"end":{"row":210,"column":2},"action":"insert","lines":["# "]},{"start":{"row":212,"column":0},"end":{"row":212,"column":2},"action":"insert","lines":["# "]},{"start":{"row":213,"column":0},"end":{"row":213,"column":2},"action":"insert","lines":["# "]}],[{"start":{"row":214,"column":0},"end":{"row":215,"column":0},"action":"insert","lines":["",""],"id":164},{"start":{"row":215,"column":0},"end":{"row":216,"column":0},"action":"insert","lines":["",""]}],[{"start":{"row":216,"column":0},"end":{"row":422,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","from sklearn.model_selection import train_test_split","import numpy as np","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Add 'movieId' column to movies_df","movies_df['movieId'] = range(1, len(movies_df) + 1)","","# Add 'type' column based on 'year'","movies_df['type'] = movies_df['year'].apply(lambda x: 'movie' if '-' not in str(x) else 'series')","","# Print columns of movies_df for debugging","print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Normalize the user-item matrix","def normalize_ratings(user_item_matrix):","    user_means = user_item_matrix.mean(axis=1)","    user_item_matrix_normalized = user_item_matrix.sub(user_means, axis=0).fillna(0)","    return user_item_matrix_normalized, user_means","","user_item_matrix_normalized, user_means = normalize_ratings(user_item_matrix)","","# Calculate user similarity matrix using the normalized matrix","user_similarity_normalized = cosine_similarity(user_item_matrix_normalized)","print(f\"User similarity matrix shape: {user_similarity_normalized.shape}\")","","# Split the data into training and test sets","train_df, test_df = train_test_split(user_interactions_df, test_size=0.2, random_state=42)","","print(f\"Training set size: {len(train_df)}\")","print(f\"Test set size: {len(test_df)}\")","","# Create the user-item matrix for the training set","train_user_item_matrix = train_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","train_user_item_matrix_normalized, train_user_means = normalize_ratings(train_user_item_matrix)","","# Calculate user similarity matrix using the training set","train_user_similarity_normalized = cosine_similarity(train_user_item_matrix_normalized)","print(f\"Training User similarity matrix shape: {train_user_similarity_normalized.shape}\")","","# Function to predict ratings using normalized data","def predict_rating_normalized(user_id, movie_id, user_similarity, user_item_matrix, user_means):","    if movie_id not in user_item_matrix.columns:","        return np.nan","","    user_index = user_item_matrix.index.get_loc(user_id)","    user_similarities = user_similarity[user_index]","    similar_users_indices = np.argsort(user_similarities)[::-1][1:]","    similar_users_ratings = user_item_matrix.iloc[similar_users_indices][movie_id]","","    weighted_sum = np.dot(user_similarities[similar_users_indices], similar_users_ratings)","    sum_of_weights = np.sum(user_similarities[similar_users_indices])","","    if sum_of_weights == 0:","        return np.nan","","    return weighted_sum / sum_of_weights + user_means[user_id]","","# Evaluate the model using MAE and MSE","def evaluate_model(test_df, user_similarity, user_item_matrix, user_means):","    y_true = []","    y_pred = []","","    for _, row in test_df.iterrows():","        user_id = row['userId']","        movie_id = row['movieId']","        true_rating = row['rating']","        predicted_rating = predict_rating_normalized(user_id, movie_id, user_similarity, user_item_matrix, user_means)","        ","        if not np.isnan(predicted_rating):","            y_true.append(true_rating)","            y_pred.append(predicted_rating)","    ","    mae = np.mean(np.abs(np.array(y_true) - np.array(y_pred)))","    mse = np.mean((np.array(y_true) - np.array(y_pred))**2)","    ","    return mae, mse","","# Evaluate the model using the test set","mae_normalized, mse_normalized = evaluate_model(test_df, train_user_similarity_normalized, train_user_item_matrix_normalized, train_user_means)","print(f\"MAE (Normalized): {mae_normalized}\")","print(f\"MSE (Normalized): {mse_normalized}\")","","# Function to get top k recommendations","def get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k=10):","    user_index = user_item_matrix.index.get_loc(user_id)","    user_similarities = user_similarity[user_index]","    similar_users_indices = user_similarities.argsort()[::-1][1:]","    ","    similar_users = user_item_matrix.iloc[similar_users_indices]","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]","    ","    top_recommendations = recommendations.sort_values(ascending=False).head(k)","    return top_recommendations.index","","# Evaluate precision and recall at k","def evaluate_precision_recall_at_k(test_df, user_similarity, user_item_matrix, k=10):","    precisions = []","    recalls = []","","    for user_id in test_df['userId'].unique():","        true_positive = test_df[test_df['userId'] == user_id]['movieId'].tolist()","        top_k_recommendations = get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k)","        ","        hits = len(set(true_positive) & set(top_k_recommendations))","        precision = hits / k","        recall = hits / len(true_positive)","        ","        precisions.append(precision)","        recalls.append(recall)","    ","    avg_precision = np.mean(precisions)","    avg_recall = np.mean(recalls)","    ","    return avg_precision, avg_recall","","# Evaluate the model using Precision@k and Recall@k","precision, recall = evaluate_precision_recall_at_k(test_df, train_user_similarity_normalized, train_user_item_matrix_normalized)","print(f\"Precision@10: {precision}\")","print(f\"Recall@10: {recall}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    user_similarities = user_similarity_normalized[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]","","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 5  # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    assert not recommendations.empty, \"No recommendations were generated.\"","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":165}],[{"start":{"row":404,"column":18},"end":{"row":404,"column":20},"action":"remove","lines":[" 5"],"id":166},{"start":{"row":404,"column":18},"end":{"row":404,"column":19},"action":"insert","lines":["9"]}],[{"start":{"row":404,"column":18},"end":{"row":404,"column":19},"action":"remove","lines":["9"],"id":167}],[{"start":{"row":404,"column":18},"end":{"row":404,"column":19},"action":"insert","lines":[" "],"id":168},{"start":{"row":404,"column":19},"end":{"row":404,"column":20},"action":"insert","lines":["8"]}],[{"start":{"row":404,"column":18},"end":{"row":404,"column":20},"action":"remove","lines":[" 8"],"id":169},{"start":{"row":404,"column":18},"end":{"row":404,"column":19},"action":"insert","lines":["4"]}],[{"start":{"row":404,"column":18},"end":{"row":404,"column":20},"action":"remove","lines":["4 "],"id":170},{"start":{"row":404,"column":18},"end":{"row":404,"column":19},"action":"insert","lines":[" "]}],[{"start":{"row":404,"column":19},"end":{"row":404,"column":20},"action":"insert","lines":["8"],"id":171}],[{"start":{"row":404,"column":19},"end":{"row":404,"column":20},"action":"remove","lines":["8"],"id":172}],[{"start":{"row":404,"column":19},"end":{"row":404,"column":20},"action":"insert","lines":["9"],"id":173}],[{"start":{"row":404,"column":19},"end":{"row":404,"column":20},"action":"remove","lines":["9"],"id":174}],[{"start":{"row":404,"column":19},"end":{"row":404,"column":20},"action":"insert","lines":["2"],"id":175},{"start":{"row":404,"column":20},"end":{"row":404,"column":21},"action":"insert","lines":["0"]},{"start":{"row":404,"column":21},"end":{"row":404,"column":22},"action":"insert","lines":["0"]}],[{"start":{"row":404,"column":21},"end":{"row":404,"column":22},"action":"remove","lines":["0"],"id":176},{"start":{"row":404,"column":20},"end":{"row":404,"column":21},"action":"remove","lines":["0"]},{"start":{"row":404,"column":19},"end":{"row":404,"column":20},"action":"remove","lines":["2"]}],[{"start":{"row":404,"column":19},"end":{"row":404,"column":20},"action":"insert","lines":["1"],"id":177},{"start":{"row":404,"column":20},"end":{"row":404,"column":21},"action":"insert","lines":["0"]},{"start":{"row":404,"column":21},"end":{"row":404,"column":22},"action":"insert","lines":["0"]}],[{"start":{"row":0,"column":0},"end":{"row":422,"column":0},"action":"remove","lines":["# import pandas as pd","# import boto3","# from io import StringIO","# from sklearn.metrics.pairwise import cosine_similarity","# from sklearn.model_selection import train_test_split","# import numpy as np","","# # Initialize the S3 client","# s3 = boto3.client('s3')","# s3_bucket_name = 'myflicksasa'","# movies_file_path = 'imdb/combined_processed.csv'","# user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","# user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# # Function to read CSV from S3","# def read_csv_from_s3(bucket_name, file_path):","#     obj = s3.get_object(Bucket=bucket_name, Key=file_path)","#     return pd.read_csv(obj['Body'])","","# # Load movie data, user profile data, and user interactions from S3","# movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","# user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","# user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","# print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","# print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","# print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# # Add 'movieId' column to movies_df","# movies_df['movieId'] = range(1, len(movies_df) + 1)","","# # Add 'type' column based on 'year'","# movies_df['type'] = movies_df['year'].apply(lambda x: 'movie' if '-' not in str(x) else 'series')","","# # Print columns of movies_df for debugging","# print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# # Ensure the movie dataset has a 'predicted_genre' column","# if 'predicted_genre' not in movies_df.columns:","#     raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# # Average ratings for duplicate user-movie interactions","# user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","# print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# # Create a user-item matrix","# user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","# print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# # Calculate user similarity matrix","# user_similarity = cosine_similarity(user_item_matrix)","# print(f\"User similarity matrix shape: {user_similarity.shape}\")","","# # Split the data into training and test sets","# train_df, test_df = train_test_split(user_interactions_df, test_size=0.2, random_state=42)","","# print(f\"Training set size: {len(train_df)}\")","# print(f\"Test set size: {len(test_df)}\")","","# # Create the user-item matrix for the training set","# train_user_item_matrix = train_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","","# # Calculate user similarity matrix using the training set","# train_user_similarity = cosine_similarity(train_user_item_matrix)","# print(f\"Training User similarity matrix shape: {train_user_similarity.shape}\")","","# # Function to predict ratings","# def predict_rating(user_id, movie_id, user_similarity, user_item_matrix):","#     if movie_id not in user_item_matrix.columns:","#         return np.nan","    ","#     # Get the indices of the similar users","#     user_index = user_item_matrix.index.get_loc(user_id)","#     user_similarities = user_similarity[user_index]","    ","#     # Exclude the target user from the list of similar users","#     similar_users_indices = np.argsort(user_similarities)[::-1][1:]","    ","#     # Get the ratings from similar users for the given movie","#     similar_users_ratings = user_item_matrix.iloc[similar_users_indices][movie_id]","    ","#     # Calculate the predicted rating as a weighted average of similar users' ratings","#     weighted_sum = np.dot(user_similarities[similar_users_indices], similar_users_ratings)","#     sum_of_weights = np.sum(user_similarities[similar_users_indices])","    ","#     if sum_of_weights == 0:","#         return np.nan","    ","#     return weighted_sum / sum_of_weights","","# # Evaluate the model using MAE and MSE","# def evaluate_model(test_df, user_similarity, user_item_matrix):","#     y_true = []","#     y_pred = []","","#     for _, row in test_df.iterrows():","#         user_id = row['userId']","#         movie_id = row['movieId']","#         true_rating = row['rating']","#         predicted_rating = predict_rating(user_id, movie_id, user_similarity, user_item_matrix)","        ","#         if not np.isnan(predicted_rating):","#             y_true.append(true_rating)","#             y_pred.append(predicted_rating)","    ","#     mae = np.mean(np.abs(np.array(y_true) - np.array(y_pred)))","#     mse = np.mean((np.array(y_true) - np.array(y_pred))**2)","    ","#     return mae, mse","","# # Evaluate the model using the test set","# mae, mse = evaluate_model(test_df, train_user_similarity, train_user_item_matrix)","# print(f\"MAE: {mae}\")","# print(f\"MSE: {mse}\")","","# # Function to get top k recommendations","# def get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k=10):","#     user_index = user_item_matrix.index.get_loc(user_id)","#     user_similarities = user_similarity[user_index]","#     similar_users_indices = user_similarities.argsort()[::-1][1:]","    ","#     similar_users = user_item_matrix.iloc[similar_users_indices]","#     similar_users_ratings = similar_users.mean(axis=0)","#     user_rated_movies = user_item_matrix.loc[user_id]","#     recommendations = similar_users_ratings[user_rated_movies == 0]","    ","#     top_recommendations = recommendations.sort_values(ascending=False).head(k)","#     return top_recommendations.index","","# # Evaluate precision and recall at k","# def evaluate_precision_recall_at_k(test_df, user_similarity, user_item_matrix, k=10):","#     precisions = []","#     recalls = []","","#     for user_id in test_df['userId'].unique():","#         true_positive = test_df[test_df['userId'] == user_id]['movieId'].tolist()","#         top_k_recommendations = get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k)","        ","#         hits = len(set(true_positive) & set(top_k_recommendations))","#         precision = hits / k","#         recall = hits / len(true_positive)","        ","#         precisions.append(precision)","#         recalls.append(recall)","    ","#     avg_precision = np.mean(precisions)","#     avg_recall = np.mean(recalls)","    ","#     return avg_precision, avg_recall","","# # Evaluate the model using Precision@k and Recall@k","# precision, recall = evaluate_precision_recall_at_k(test_df, train_user_similarity, train_user_item_matrix)","# print(f\"Precision@10: {precision}\")","# print(f\"Recall@10: {recall}\")","","# # Function to recommend movies based on user similarity","# def recommend_movies_collaborative(user_id, n_recommendations=10):","#     if user_id not in user_item_matrix.index:","#         raise ValueError(f\"No user found with user_id: {user_id}\")","","#     # Get the user's similarity scores with other users","#     user_similarities = user_similarity[user_item_matrix.index.get_loc(user_id)]","#     similar_users_indices = user_similarities.argsort()[::-1][1:]  # Exclude the user itself","","#     similar_users = user_item_matrix.iloc[similar_users_indices]","#     print(f\"Found {len(similar_users)} similar users\")","","#     # Aggregate ratings from similar users","#     similar_users_ratings = similar_users.mean(axis=0)","#     user_rated_movies = user_item_matrix.loc[user_id]","#     recommendations = similar_users_ratings[user_rated_movies == 0]  # Exclude already rated movies","","#     # Get top recommendations","#     top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","#     recommended_movie_ids = top_recommendations.index","","#     # Debugging information","#     print(f\"Recommended movie IDs: {recommended_movie_ids}\")","","#     # Check data types","#     print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","#     print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","#     # Convert types if necessary","#     if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","#         recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","#     recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","#     return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# # Test function to verify the collaborative recommendation logic","# def test_recommend_movies_collaborative():","#     test_user_id =5  # Update user ID","#     try:","#         recommendations = recommend_movies_collaborative(test_user_id)","#     except Exception as e:","#         print(f\"Error during test_recommend_movies_collaborative: {e}\")","#         return","    ","#     # Ensure recommendations are returned","#     assert not recommendations.empty, \"No recommendations were generated.\"","    ","#     # Verify the number of recommendations is up to n_recommendations","#     assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","#     # Print the recommendations for debugging","#     print(\"Recommendations:\\n\", recommendations)","","# def run_tests():","#     test_recommend_movies_collaborative()","#     print(\"All tests passed.\")","","# # Run the tests","# run_tests()","","","import pandas as pd","import boto3","from io import StringIO","from sklearn.metrics.pairwise import cosine_similarity","from sklearn.model_selection import train_test_split","import numpy as np","","# Initialize the S3 client","s3 = boto3.client('s3')","s3_bucket_name = 'myflicksasa'","movies_file_path = 'imdb/combined_processed.csv'","user_profiles_file_path = 'imdb/simulated_user_profiles.csv'","user_interactions_file_path = 'imdb/simulated_user_interactions.csv'","","# Function to read CSV from S3","def read_csv_from_s3(bucket_name, file_path):","    obj = s3.get_object(Bucket=bucket_name, Key=file_path)","    return pd.read_csv(obj['Body'])","","# Load movie data, user profile data, and user interactions from S3","movies_df = read_csv_from_s3(s3_bucket_name, movies_file_path)","user_profiles_df = read_csv_from_s3(s3_bucket_name, user_profiles_file_path)","user_interactions_df = read_csv_from_s3(s3_bucket_name, user_interactions_file_path)","","print(f\"Loaded {len(movies_df)} movies from {movies_file_path}\")","print(f\"Loaded {len(user_profiles_df)} user profiles from {user_profiles_file_path}\")","print(f\"Loaded {len(user_interactions_df)} user interactions from {user_interactions_file_path}\")","","# Add 'movieId' column to movies_df","movies_df['movieId'] = range(1, len(movies_df) + 1)","","# Add 'type' column based on 'year'","movies_df['type'] = movies_df['year'].apply(lambda x: 'movie' if '-' not in str(x) else 'series')","","# Print columns of movies_df for debugging","print(f\"Movies DataFrame columns: {movies_df.columns}\")","","# Ensure the movie dataset has a 'predicted_genre' column","if 'predicted_genre' not in movies_df.columns:","    raise KeyError(\"'predicted_genre' column is missing in movies_df\")","","# Average ratings for duplicate user-movie interactions","user_interactions_df = user_interactions_df.groupby(['userId', 'movieId']).agg({'rating': 'mean'}).reset_index()","print(f\"User interactions after averaging duplicates: {len(user_interactions_df)} records\")","","# Create a user-item matrix","user_item_matrix = user_interactions_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","print(f\"User-Item matrix shape: {user_item_matrix.shape}\")","","# Normalize the user-item matrix","def normalize_ratings(user_item_matrix):","    user_means = user_item_matrix.mean(axis=1)","    user_item_matrix_normalized = user_item_matrix.sub(user_means, axis=0).fillna(0)","    return user_item_matrix_normalized, user_means","","user_item_matrix_normalized, user_means = normalize_ratings(user_item_matrix)","","# Calculate user similarity matrix using the normalized matrix","user_similarity_normalized = cosine_similarity(user_item_matrix_normalized)","print(f\"User similarity matrix shape: {user_similarity_normalized.shape}\")","","# Split the data into training and test sets","train_df, test_df = train_test_split(user_interactions_df, test_size=0.2, random_state=42)","","print(f\"Training set size: {len(train_df)}\")","print(f\"Test set size: {len(test_df)}\")","","# Create the user-item matrix for the training set","train_user_item_matrix = train_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)","train_user_item_matrix_normalized, train_user_means = normalize_ratings(train_user_item_matrix)","","# Calculate user similarity matrix using the training set","train_user_similarity_normalized = cosine_similarity(train_user_item_matrix_normalized)","print(f\"Training User similarity matrix shape: {train_user_similarity_normalized.shape}\")","","# Function to predict ratings using normalized data","def predict_rating_normalized(user_id, movie_id, user_similarity, user_item_matrix, user_means):","    if movie_id not in user_item_matrix.columns:","        return np.nan","","    user_index = user_item_matrix.index.get_loc(user_id)","    user_similarities = user_similarity[user_index]","    similar_users_indices = np.argsort(user_similarities)[::-1][1:]","    similar_users_ratings = user_item_matrix.iloc[similar_users_indices][movie_id]","","    weighted_sum = np.dot(user_similarities[similar_users_indices], similar_users_ratings)","    sum_of_weights = np.sum(user_similarities[similar_users_indices])","","    if sum_of_weights == 0:","        return np.nan","","    return weighted_sum / sum_of_weights + user_means[user_id]","","# Evaluate the model using MAE and MSE","def evaluate_model(test_df, user_similarity, user_item_matrix, user_means):","    y_true = []","    y_pred = []","","    for _, row in test_df.iterrows():","        user_id = row['userId']","        movie_id = row['movieId']","        true_rating = row['rating']","        predicted_rating = predict_rating_normalized(user_id, movie_id, user_similarity, user_item_matrix, user_means)","        ","        if not np.isnan(predicted_rating):","            y_true.append(true_rating)","            y_pred.append(predicted_rating)","    ","    mae = np.mean(np.abs(np.array(y_true) - np.array(y_pred)))","    mse = np.mean((np.array(y_true) - np.array(y_pred))**2)","    ","    return mae, mse","","# Evaluate the model using the test set","mae_normalized, mse_normalized = evaluate_model(test_df, train_user_similarity_normalized, train_user_item_matrix_normalized, train_user_means)","print(f\"MAE (Normalized): {mae_normalized}\")","print(f\"MSE (Normalized): {mse_normalized}\")","","# Function to get top k recommendations","def get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k=10):","    user_index = user_item_matrix.index.get_loc(user_id)","    user_similarities = user_similarity[user_index]","    similar_users_indices = user_similarities.argsort()[::-1][1:]","    ","    similar_users = user_item_matrix.iloc[similar_users_indices]","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]","    ","    top_recommendations = recommendations.sort_values(ascending=False).head(k)","    return top_recommendations.index","","# Evaluate precision and recall at k","def evaluate_precision_recall_at_k(test_df, user_similarity, user_item_matrix, k=10):","    precisions = []","    recalls = []","","    for user_id in test_df['userId'].unique():","        true_positive = test_df[test_df['userId'] == user_id]['movieId'].tolist()","        top_k_recommendations = get_top_k_recommendations(user_id, user_similarity, user_item_matrix, k)","        ","        hits = len(set(true_positive) & set(top_k_recommendations))","        precision = hits / k","        recall = hits / len(true_positive)","        ","        precisions.append(precision)","        recalls.append(recall)","    ","    avg_precision = np.mean(precisions)","    avg_recall = np.mean(recalls)","    ","    return avg_precision, avg_recall","","# Evaluate the model using Precision@k and Recall@k","precision, recall = evaluate_precision_recall_at_k(test_df, train_user_similarity_normalized, train_user_item_matrix_normalized)","print(f\"Precision@10: {precision}\")","print(f\"Recall@10: {recall}\")","","# Function to recommend movies based on user similarity","def recommend_movies_collaborative(user_id, n_recommendations=10):","    if user_id not in user_item_matrix.index:","        raise ValueError(f\"No user found with user_id: {user_id}\")","","    user_similarities = user_similarity_normalized[user_item_matrix.index.get_loc(user_id)]","    similar_users_indices = user_similarities.argsort()[::-1][1:]","","    similar_users = user_item_matrix.iloc[similar_users_indices]","    print(f\"Found {len(similar_users)} similar users\")","","    similar_users_ratings = similar_users.mean(axis=0)","    user_rated_movies = user_item_matrix.loc[user_id]","    recommendations = similar_users_ratings[user_rated_movies == 0]","","    top_recommendations = recommendations.sort_values(ascending=False).head(n_recommendations)","    recommended_movie_ids = top_recommendations.index","","    print(f\"Recommended movie IDs: {recommended_movie_ids}\")","    print(f\"Data type of recommended_movie_ids: {recommended_movie_ids.dtype}\")","    print(f\"Data type of movies_df['movieId']: {movies_df['movieId'].dtype}\")","","    if recommended_movie_ids.dtype != movies_df['movieId'].dtype:","        recommended_movie_ids = recommended_movie_ids.astype(movies_df['movieId'].dtype)","","    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]","    return recommended_movies[['title', 'description', 'type', 'rating', 'predicted_genre']]","","# Test function to verify the collaborative recommendation logic","def test_recommend_movies_collaborative():","    test_user_id = 100 # Update user ID","    try:","        recommendations = recommend_movies_collaborative(test_user_id)","    except Exception as e:","        print(f\"Error during test_recommend_movies_collaborative: {e}\")","        return","    ","    assert not recommendations.empty, \"No recommendations were generated.\"","    assert len(recommendations) <= 10, \"The number of recommendations is incorrect.\"","","    print(\"Recommendations:\\n\", recommendations)","","def run_tests():","    test_recommend_movies_collaborative()","    print(\"All tests passed.\")","","# Run the tests","run_tests()",""],"id":178}],[{"start":{"row":0,"column":0},"end":{"row":64,"column":0},"action":"insert","lines":["import pandas as pd","from surprise import Dataset, Reader, SVD","from surprise.model_selection import train_test_split","from surprise.accuracy import mae, rmse","from surprise import accuracy","","# Load the datasets","movies_df = pd.read_csv('imdb/combined_processed.csv')","interactions_df = pd.read_csv('imdb/simulated_user_interactions.csv')","","# Print the first few rows of the datasets","print(\"Movies DataFrame:\")","print(movies_df.head())","print(\"Interactions DataFrame:\")","print(interactions_df.head())","","# Prepare the data for Surprise","reader = Reader(rating_scale=(1, 5))","data = Dataset.load_from_df(interactions_df[['userId', 'movieId', 'rating']], reader)","","# Split the data into training and testing sets","trainset, testset = train_test_split(data, test_size=0.2, random_state=42)","","# Train the SVD algorithm","algo = SVD()","algo.fit(trainset)","","# Make predictions on the test set","predictions = algo.test(testset)","","# Calculate accuracy metrics","print(\"Mean Absolute Error (MAE):\")","mae(predictions)","print(\"Root Mean Squared Error (RMSE):\")","rmse(predictions)","","# Function to get movie recommendations for a specific user","def get_recommendations(user_id, num_recommendations=10):","    # Get a list of all movie IDs","    all_movie_ids = movies_df['movieId'].tolist()","    ","    # Get the movies the user has already rated","    rated_movies = interactions_df[interactions_df['userId'] == user_id]['movieId'].tolist()","    ","    # Get predictions for all movies the user hasn't rated yet","    predictions = [algo.predict(user_id, movie_id) for movie_id in all_movie_ids if movie_id not in rated_movies]","    ","    # Sort the predictions by estimated rating","    predictions.sort(key=lambda x: x.est, reverse=True)","    ","    # Get the top N recommendations","    top_n_predictions = predictions[:num_recommendations]","    ","    # Get the movie details for the top N recommendations","    top_n_movie_ids = [pred.iid for pred in top_n_predictions]","    recommended_movies = movies_df[movies_df['movieId'].isin(top_n_movie_ids)]","    ","    return recommended_movies","","# Example usage: Get recommendations for a specific user","user_id = 1  # Change this to the user ID you want to get recommendations for","recommendations = get_recommendations(user_id)","print(f\"Top 10 movie recommendations for user {user_id}:\")","print(recommendations[['title', 'description', 'rating']])",""],"id":179}],[{"start":{"row":0,"column":0},"end":{"row":64,"column":0},"action":"remove","lines":["import pandas as pd","from surprise import Dataset, Reader, SVD","from surprise.model_selection import train_test_split","from surprise.accuracy import mae, rmse","from surprise import accuracy","","# Load the datasets","movies_df = pd.read_csv('imdb/combined_processed.csv')","interactions_df = pd.read_csv('imdb/simulated_user_interactions.csv')","","# Print the first few rows of the datasets","print(\"Movies DataFrame:\")","print(movies_df.head())","print(\"Interactions DataFrame:\")","print(interactions_df.head())","","# Prepare the data for Surprise","reader = Reader(rating_scale=(1, 5))","data = Dataset.load_from_df(interactions_df[['userId', 'movieId', 'rating']], reader)","","# Split the data into training and testing sets","trainset, testset = train_test_split(data, test_size=0.2, random_state=42)","","# Train the SVD algorithm","algo = SVD()","algo.fit(trainset)","","# Make predictions on the test set","predictions = algo.test(testset)","","# Calculate accuracy metrics","print(\"Mean Absolute Error (MAE):\")","mae(predictions)","print(\"Root Mean Squared Error (RMSE):\")","rmse(predictions)","","# Function to get movie recommendations for a specific user","def get_recommendations(user_id, num_recommendations=10):","    # Get a list of all movie IDs","    all_movie_ids = movies_df['movieId'].tolist()","    ","    # Get the movies the user has already rated","    rated_movies = interactions_df[interactions_df['userId'] == user_id]['movieId'].tolist()","    ","    # Get predictions for all movies the user hasn't rated yet","    predictions = [algo.predict(user_id, movie_id) for movie_id in all_movie_ids if movie_id not in rated_movies]","    ","    # Sort the predictions by estimated rating","    predictions.sort(key=lambda x: x.est, reverse=True)","    ","    # Get the top N recommendations","    top_n_predictions = predictions[:num_recommendations]","    ","    # Get the movie details for the top N recommendations","    top_n_movie_ids = [pred.iid for pred in top_n_predictions]","    recommended_movies = movies_df[movies_df['movieId'].isin(top_n_movie_ids)]","    ","    return recommended_movies","","# Example usage: Get recommendations for a specific user","user_id = 1  # Change this to the user ID you want to get recommendations for","recommendations = get_recommendations(user_id)","print(f\"Top 10 movie recommendations for user {user_id}:\")","print(recommendations[['title', 'description', 'rating']])",""],"id":180},{"start":{"row":0,"column":0},"end":{"row":76,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from surprise import Dataset, Reader, SVD","from surprise.model_selection import train_test_split","from surprise.accuracy import mae, rmse","","# Initialize the S3 client","s3_client = boto3.client('s3')","","# Function to load CSV data from S3","def load_csv_from_s3(bucket_name, file_key):","    csv_obj = s3_client.get_object(Bucket=bucket_name, Key=file_key)","    body = csv_obj['Body']","    csv_string = body.read().decode('utf-8')","    return pd.read_csv(StringIO(csv_string))","","# Load datasets from S3","bucket_name = 'myFlicksasa'","movies_df = load_csv_from_s3(bucket_name, 'imdb/combined_processed.csv')","interactions_df = load_csv_from_s3(bucket_name, 'imdb/simulated_user_interactions.csv')","","# Print the first few rows of the datasets","print(\"Movies DataFrame:\")","print(movies_df.head())","print(\"Interactions DataFrame:\")","print(interactions_df.head())","","# Prepare the data for Surprise","reader = Reader(rating_scale=(1, 5))","data = Dataset.load_from_df(interactions_df[['userId', 'movieId', 'rating']], reader)","","# Split the data into training and testing sets","trainset, testset = train_test_split(data, test_size=0.2, random_state=42)","","# Train the SVD algorithm","algo = SVD()","algo.fit(trainset)","","# Make predictions on the test set","predictions = algo.test(testset)","","# Calculate accuracy metrics","print(\"Mean Absolute Error (MAE):\")","mae(predictions)","print(\"Root Mean Squared Error (RMSE):\")","rmse(predictions)","","# Function to get movie recommendations for a specific user","def get_recommendations(user_id, num_recommendations=10):","    # Get a list of all movie IDs","    all_movie_ids = movies_df['movieId'].tolist()","    ","    # Get the movies the user has already rated","    rated_movies = interactions_df[interactions_df['userId'] == user_id]['movieId'].tolist()","    ","    # Get predictions for all movies the user hasn't rated yet","    predictions = [algo.predict(user_id, movie_id) for movie_id in all_movie_ids if movie_id not in rated_movies]","    ","    # Sort the predictions by estimated rating","    predictions.sort(key=lambda x: x.est, reverse=True)","    ","    # Get the top N recommendations","    top_n_predictions = predictions[:num_recommendations]","    ","    # Get the movie details for the top N recommendations","    top_n_movie_ids = [pred.iid for pred in top_n_predictions]","    recommended_movies = movies_df[movies_df['movieId'].isin(top_n_movie_ids)]","    ","    return recommended_movies","","# Example usage: Get recommendations for a specific user","user_id = 1  # Change this to the user ID you want to get recommendations for","recommendations = get_recommendations(user_id)","print(f\"Top 10 movie recommendations for user {user_id}:\")","print(recommendations[['title', 'description', 'rating']])",""]}],[{"start":{"row":18,"column":14},"end":{"row":18,"column":27},"action":"remove","lines":["'myFlicksasa'"],"id":181},{"start":{"row":18,"column":14},"end":{"row":18,"column":27},"action":"insert","lines":["'myflicksasa'"]}],[{"start":{"row":0,"column":0},"end":{"row":76,"column":0},"action":"remove","lines":["import pandas as pd","import boto3","from io import StringIO","from surprise import Dataset, Reader, SVD","from surprise.model_selection import train_test_split","from surprise.accuracy import mae, rmse","","# Initialize the S3 client","s3_client = boto3.client('s3')","","# Function to load CSV data from S3","def load_csv_from_s3(bucket_name, file_key):","    csv_obj = s3_client.get_object(Bucket=bucket_name, Key=file_key)","    body = csv_obj['Body']","    csv_string = body.read().decode('utf-8')","    return pd.read_csv(StringIO(csv_string))","","# Load datasets from S3","bucket_name = 'myflicksasa'","movies_df = load_csv_from_s3(bucket_name, 'imdb/combined_processed.csv')","interactions_df = load_csv_from_s3(bucket_name, 'imdb/simulated_user_interactions.csv')","","# Print the first few rows of the datasets","print(\"Movies DataFrame:\")","print(movies_df.head())","print(\"Interactions DataFrame:\")","print(interactions_df.head())","","# Prepare the data for Surprise","reader = Reader(rating_scale=(1, 5))","data = Dataset.load_from_df(interactions_df[['userId', 'movieId', 'rating']], reader)","","# Split the data into training and testing sets","trainset, testset = train_test_split(data, test_size=0.2, random_state=42)","","# Train the SVD algorithm","algo = SVD()","algo.fit(trainset)","","# Make predictions on the test set","predictions = algo.test(testset)","","# Calculate accuracy metrics","print(\"Mean Absolute Error (MAE):\")","mae(predictions)","print(\"Root Mean Squared Error (RMSE):\")","rmse(predictions)","","# Function to get movie recommendations for a specific user","def get_recommendations(user_id, num_recommendations=10):","    # Get a list of all movie IDs","    all_movie_ids = movies_df['movieId'].tolist()","    ","    # Get the movies the user has already rated","    rated_movies = interactions_df[interactions_df['userId'] == user_id]['movieId'].tolist()","    ","    # Get predictions for all movies the user hasn't rated yet","    predictions = [algo.predict(user_id, movie_id) for movie_id in all_movie_ids if movie_id not in rated_movies]","    ","    # Sort the predictions by estimated rating","    predictions.sort(key=lambda x: x.est, reverse=True)","    ","    # Get the top N recommendations","    top_n_predictions = predictions[:num_recommendations]","    ","    # Get the movie details for the top N recommendations","    top_n_movie_ids = [pred.iid for pred in top_n_predictions]","    recommended_movies = movies_df[movies_df['movieId'].isin(top_n_movie_ids)]","    ","    return recommended_movies","","# Example usage: Get recommendations for a specific user","user_id = 1  # Change this to the user ID you want to get recommendations for","recommendations = get_recommendations(user_id)","print(f\"Top 10 movie recommendations for user {user_id}:\")","print(recommendations[['title', 'description', 'rating']])",""],"id":182},{"start":{"row":0,"column":0},"end":{"row":79,"column":0},"action":"insert","lines":["import pandas as pd","import boto3","from io import StringIO","from surprise import Dataset, Reader, SVD","from surprise.model_selection import train_test_split","from surprise.accuracy import mae, rmse","","# Initialize the S3 client","s3_client = boto3.client('s3')","","# Function to load CSV data from S3","def load_csv_from_s3(bucket_name, file_key):","    csv_obj = s3_client.get_object(Bucket=bucket_name, Key=file_key)","    body = csv_obj['Body']","    csv_string = body.read().decode('utf-8')","    return pd.read_csv(StringIO(csv_string))","","# Load datasets from S3","bucket_name = 'myFlicksasa'","movies_df = load_csv_from_s3(bucket_name, 'imdb/combined_processed.csv')","interactions_df = load_csv_from_s3(bucket_name, 'imdb/simulated_user_interactions.csv')","","# Add the movieId column to movies_df","movies_df['movieId'] = range(1, len(movies_df) + 1)","","# Print the first few rows of the datasets","print(\"Movies DataFrame:\")","print(movies_df.head())","print(\"Interactions DataFrame:\")","print(interactions_df.head())","","# Prepare the data for Surprise","reader = Reader(rating_scale=(1, 5))","data = Dataset.load_from_df(interactions_df[['userId', 'movieId', 'rating']], reader)","","# Split the data into training and testing sets","trainset, testset = train_test_split(data, test_size=0.2, random_state=42)","","# Train the SVD algorithm","algo = SVD()","algo.fit(trainset)","","# Make predictions on the test set","predictions = algo.test(testset)","","# Calculate accuracy metrics","print(\"Mean Absolute Error (MAE):\")","mae(predictions)","print(\"Root Mean Squared Error (RMSE):\")","rmse(predictions)","","# Function to get movie recommendations for a specific user","def get_recommendations(user_id, num_recommendations=10):","    # Get a list of all movie IDs","    all_movie_ids = movies_df['movieId'].tolist()","    ","    # Get the movies the user has already rated","    rated_movies = interactions_df[interactions_df['userId'] == user_id]['movieId'].tolist()","    ","    # Get predictions for all movies the user hasn't rated yet","    predictions = [algo.predict(user_id, movie_id) for movie_id in all_movie_ids if movie_id not in rated_movies]","    ","    # Sort the predictions by estimated rating","    predictions.sort(key=lambda x: x.est, reverse=True)","    ","    # Get the top N recommendations","    top_n_predictions = predictions[:num_recommendations]","    ","    # Get the movie details for the top N recommendations","    top_n_movie_ids = [pred.iid for pred in top_n_predictions]","    recommended_movies = movies_df[movies_df['movieId'].isin(top_n_movie_ids)]","    ","    return recommended_movies","","# Example usage: Get recommendations for a specific user","user_id = 1  # Change this to the user ID you want to get recommendations for","recommendations = get_recommendations(user_id)","print(f\"Top 10 movie recommendations for user {user_id}:\")","print(recommendations[['title', 'description', 'rating']])",""]}],[{"start":{"row":18,"column":16},"end":{"row":18,"column":17},"action":"remove","lines":["y"],"id":183}],[{"start":{"row":18,"column":16},"end":{"row":18,"column":17},"action":"insert","lines":["f"],"id":184}],[{"start":{"row":18,"column":16},"end":{"row":18,"column":17},"action":"remove","lines":["f"],"id":185}],[{"start":{"row":18,"column":16},"end":{"row":18,"column":17},"action":"insert","lines":["y"],"id":186}],[{"start":{"row":18,"column":17},"end":{"row":18,"column":18},"action":"remove","lines":["F"],"id":187}],[{"start":{"row":18,"column":17},"end":{"row":18,"column":18},"action":"insert","lines":["f"],"id":188}]]},"ace":{"folds":[],"scrolltop":483.818162673211,"scrollleft":0,"selection":{"start":{"row":38,"column":0},"end":{"row":40,"column":18},"isBackwards":true},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":{"row":0,"state":"start","mode":"ace/mode/python"}},"timestamp":1721928229749,"hash":"35a396892e0db1117f7458c041492446bd7cf496"}